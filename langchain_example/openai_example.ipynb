{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install langchain\n",
    "# !pip install python-dotenv\n",
    "# !pip install pypdf\n",
    "# !pip install chromadb\n",
    "# !pip install sentence-transformers\n",
    "# !pip install openai\n",
    "# !pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.embeddings import (\n",
    "    HuggingFaceEmbeddings,\n",
    "    HuggingFaceBgeEmbeddings,\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import fitz\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text_by_red_strikethrough_status(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    strikethrough_texts = []\n",
    "    non_strikethrough_texts = []\n",
    "    full_texts = []\n",
    "\n",
    "    for page_number in range(len(document)):\n",
    "        page = document[page_number]\n",
    "        words = page.get_text(\"words\")  # 단어와 그 위치를 반환\n",
    "        paths = page.get_drawings()  # 페이지의 그래픽 요소를 추출\n",
    "\n",
    "        strikethrough_lines = []\n",
    "\n",
    "        # 그림 요소 중에서 선과 사각형을 검사하여 빨간색 취소선으로 판단\n",
    "        for path in paths:\n",
    "            color = path[\"color\"]\n",
    "            # 선의 색상이 빨간색인 경우에만 처리\n",
    "            if color == (1, 0, 0):  # RGB 색상으로 빨간색 확인\n",
    "                for item in path[\"items\"]:\n",
    "                    if item[0] == \"l\":  # 선인 경우\n",
    "                        p1, p2 = item[1:]\n",
    "                        if p1.y == p2.y:  # 수평선이면\n",
    "                            rect = fitz.Rect(p1.x, p1.y - 1, p2.x, p2.y + 1)\n",
    "                            strikethrough_lines.append(rect)\n",
    "                    elif item[0] == \"re\":  # 사각형인 경우\n",
    "                        rect = item[1]\n",
    "                        if rect.width > rect.height and rect.height < 3:  # 넓이가 높이보다 많이 크고 높이가 3pt 이하이면\n",
    "                            strikethrough_lines.append(rect)\n",
    "\n",
    "        # 각 단어와 취소선이 겹치는지 검사\n",
    "        same_line = words[0][5]\n",
    "        previous_strike = False\n",
    "        strike_line = ''\n",
    "        line = ''\n",
    "        for word in words:\n",
    "            word_rect = fitz.Rect(word[:4])  # 단어의 위치\n",
    "            strikethrough_found = False\n",
    "            for line_rect in strikethrough_lines:\n",
    "                if word_rect.intersects(line_rect):  # 겹치면\n",
    "                    strikethrough_found = True\n",
    "                    break\n",
    "            if not strikethrough_found:  # 취소선이 없으면\n",
    "                non_strikethrough_texts.append(word[4:6])  # 취소선이 적용되지 않은 단어 추가\n",
    "                if same_line != word[5]:\n",
    "                    same_line = word[5]\n",
    "                    line += '\\n'\n",
    "\n",
    "                line = line + ' ' + word[4]\n",
    "                \n",
    "                if strikethrough_found != previous_strike:\n",
    "                    full_texts.append('말소기록(' + strike_line + ')')\n",
    "                    strike_line = ''\n",
    "                previous_strike = False\n",
    "            else:\n",
    "                strikethrough_texts.append(word[4:6])  # 취소선이 적용된 단어 추가\n",
    "                strike_line = strike_line  + ' ' + word[4]\n",
    "                if strikethrough_found != previous_strike:\n",
    "                    full_texts.append(line + '\\n')\n",
    "                    line=''\n",
    "                previous_strike = True\n",
    "        full_texts.append(line)\n",
    "    document.close()\n",
    "    return strikethrough_texts, non_strikethrough_texts, full_texts\n",
    "\n",
    "def re_text(full_texts):\n",
    "    full = ''\n",
    "    for text in full_texts:\n",
    "        cleaned_text = re.sub(r'\\.\\s*\\.', '', text)\n",
    "        full += cleaned_text\n",
    "    return full\n",
    "\n",
    "pdf_path = 'real_data_ex.pdf'\n",
    "strikethrough_texts, non_strikethrough_texts, full_texts = find_text_by_red_strikethrough_status(pdf_path)\n",
    "texts = re_text(full_texts)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "split_texts = text_splitter.split_text(texts)\n",
    "pages = text_splitter.create_documents(split_texts)\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'chroma_store'\n",
    "\n",
    "embeddings_open = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vector_index = Chroma.from_documents(\n",
    "    pages, # Documents\n",
    "    embedding = embeddings_open , # Text embedding model\n",
    "    persist_directory=directory # persists the vectors to the file system\n",
    "    )\n",
    "vector_index.persist()\n",
    "print('count: ', vector_index._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "prompt_korean = ChatPromptTemplate.from_template(\"\"\"\n",
    "너는 문서를 보고 대답을 하는 전문가야 모르는 답은 모른다고 답을 해줘\n",
    "문서를 보면 \"말소기록()\" 괄호로 묶인 텍스트가 있는데 이거는 말소된 기록이란 뜻이야.\n",
    "내가 말소기록을 요청할 경우에만 말소기록()을 사용하고 나머지 경우는 사용하지 마.\n",
    "답변은 무조건 한국말로 해줘\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {question}\n",
    "\"\"\")\n",
    "\n",
    "retriever = vector_index.as_retriever(\n",
    "    search_type=\"similarity\", # Cosine Similarity\n",
    "    search_kwargs={\n",
    "        \"k\": 5, # Select top k search results\n",
    "    } \n",
    ")\n",
    "\n",
    "open_llm = ChatOpenAI(\n",
    "    temperature=0.5,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-3.5-turbo\",  # 모델명\n",
    ")\n",
    "\n",
    "conv_chain = ConversationalRetrievalChain.from_llm(\n",
    "    open_llm, \n",
    "    retriever=retriever,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt_korean},\n",
    "    memory=memory\n",
    ")\n",
    "# query_list = [\"이 회사의 상호가 뭐지\",\"회사 상호를 영어로 바꾸면 뭐지?\", \"본점이 어디지\",\n",
    "#                \"발행주식의 총수가 뭐지\", \"발행할 주식의 총수는 뭐지?\", \"액면가는 얼마지\",\n",
    "#                \"말소된 기록은 뭐가 있지\", \"회사성립연월인은 언제지\", \"등기번호가 뭐지\", \"등록번호는 뭐지\"\n",
    "#                ]\n",
    "query_list = [\"회사의 상호, 상호의 영어명, 본점, 발행한 주식의 총수, 발행할 주식의 총수, 액면가, 회사성립연월일, 등기번호, 등록번호에 대해 알려줘\"]\n",
    "\n",
    "for query in query_list:\n",
    "    result = conv_chain.invoke({\"question\": query, \"chat_history\": chat_history})\n",
    "    print(result)\n",
    "    chat_history.append((query, result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_llm = ChatOpenAI(\n",
    "    temperature=0.5,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-3.5-turbo\",  # 모델명\n",
    ")\n",
    "\n",
    "conv_chain = ConversationalRetrievalChain.from_llm(\n",
    "    open_llm, \n",
    "    retriever=retriever,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt_korean},\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "query = \"종류주식의 내용에 대해 요약해줘\"\n",
    "result = conv_chain.invoke({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
