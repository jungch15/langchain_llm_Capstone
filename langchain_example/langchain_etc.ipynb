{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install langchain\n",
    "# !pip install python-dotenv\n",
    "# !pip install pypdf\n",
    "# !pip install chromadb\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.embeddings import (\n",
    "    HuggingFaceEmbeddings,\n",
    "    HuggingFaceBgeEmbeddings,\n",
    ")\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## txt\n",
    "loader = TextLoader(\"C:\\\\Users\\\\shOh\\\\Downloads\\\\capstone\\\\langchain\\\\test.txt\", encoding='utf8')\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap  = 100,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(data[0].page_content)\n",
    "pages = loader.load_and_split(text_splitter)\n",
    "\n",
    "##pdf\n",
    "# loader = PyPDFLoader(\"real_data_ex.pdf\")\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size = 500,\n",
    "#     chunk_overlap  = 100,\n",
    "#     length_function = len,\n",
    "# )\n",
    "\n",
    "# pages = loader.load_and_split(text_splitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:  18\n"
     ]
    }
   ],
   "source": [
    "directory = 'chroma_store'\n",
    "vector_index = Chroma.from_documents(\n",
    "    pages, # Documents\n",
    "    HuggingFaceEmbeddings(), # Text embedding model\n",
    "    persist_directory=directory # persists the vectors to the file system\n",
    "    )\n",
    "vector_index.persist()\n",
    "print('count: ', vector_index._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_index.as_retriever(\n",
    "    search_type=\"mmr\", # Cosine Similarity\n",
    "    search_kwargs={\n",
    "        \"k\": 5, # Select top k search results\n",
    "    } \n",
    ")\n",
    "# retriever.get_relevant_documents(\"상호가 뭐지?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\shOh\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, \n",
    "    # max_new_tokens=256,  \n",
    "    temperature=0.1, \n",
    "    callbacks=[StreamingStdOutCallbackHandler()], \n",
    "    streaming=True,  \n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "# qa_chain.invoke('이전 본점 위치들 말해줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 정보 삭제\n",
    "# ids = vector_index.get(0)['ids']\n",
    "\n",
    "# print('before: ', vector_index._collection.count())\n",
    "# for i in ids:\n",
    "#     vector_index._collection.delete(ids=i)\n",
    "# print('after :', vector_index._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 18, updating n_results = 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer: 본점은 서울특별시 강남구 테헤란로 302, 11층 100호(역삼동, 위워크타워)입니다.</s>"
     ]
    }
   ],
   "source": [
    "# 만들어놓은 벡터 retriever와 document_chain 연동\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "해당 질문에 대해서 오직 주어진 context만을 기반하여 한국어로 답변을 작성해줘:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "retriever = vector_index.as_retriever(\n",
    "    search_type=\"mmr\", # Cosine Similarity\n",
    "    search_kwargs={\n",
    "        \"k\": 5, # Select top k search results\n",
    "    } \n",
    ")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# retrieval chain에 질문 넣어서 답변 생성\n",
    "response = retrieval_chain.invoke({\"input\": \"본점이 어디지?\"})\n",
    "# print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 18, updating n_results = 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "Answer: 현재 발행주식의 총수는 176,890 주입니다.</s>"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"아래의 문맥과 지금까지 나눴던 대화를 바탕으로 한국어로 사용자의 질문에 답변:\\\\n\\\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt) #retriever이랑 chat history 기반 \n",
    "\n",
    "# 대화형으로 답변 생성\n",
    "query = \"발행주식총수가 몇개지\"\n",
    "result = retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": query\n",
    "    })\n",
    "chat_history.append((HumanMessage(content=query), AIMessage(content=result['answer'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
